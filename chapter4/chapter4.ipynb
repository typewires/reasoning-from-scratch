{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc484797",
   "metadata": {},
   "source": [
    "# Chapter 4: Improving Reasoning with Inference-Time Scaling\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand inference-time compute scaling as a way to improve accuracy without retraining\n",
    "- Implement chain-of-thought prompting to encourage step-by-step reasoning\n",
    "- Build self-consistency sampling with majority voting\n",
    "- Create flexible text generation with swappable sampling strategies (temperature, top-p)\n",
    "\n",
    "## Core Techniques (notes from the chapter)\n",
    "\n",
    "- Method 1: Extending the chain-of-thought response to prompt the model to explain its reasoning. This is a simple technique that can substantially improve accuracy. \n",
    "- Method 2: Parallel sampling via self-consistency, where the model generates multiple responses and selects the most frequent one. \n",
    "- Method 3: Iterative self-refinement, where the model reviews and improves its own reasoning and answers across multiple steps. (This topic is implemented and covered in more detail in the next chapter.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c0ec3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Silicon GPU (MPS)\n",
      "âœ“ qwen3/qwen3-0.6B-base.pth already up-to-date\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from reasoning_from_scratch.ch02 import get_device\n",
    "from reasoning_from_scratch.ch03 import load_model_and_tokenizer\n",
    "\n",
    "device = get_device()\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model, tokenizer = load_model_and_tokenizer(\n",
    "    which_model=\"base\",\n",
    "    device=device,\n",
    "    use_compile=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b35c55ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful math assistant.\n",
      "Answer the question and write the final result on a new line as:\n",
      "\\boxed{ANSWER}\n",
      "\n",
      "Question:\n",
      "Half the value of $3x-9$ is $x+37$. What is the value of $x$?\n",
      "\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from reasoning_from_scratch.ch03 import render_prompt\n",
    "\n",
    "raw_prompt = (\n",
    "    \"Half the value of $3x-9$ is $x+37$. \"\n",
    "    \"What is the value of $x$?\"\n",
    ")\n",
    "prompt = render_prompt(raw_prompt)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7a408c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reasoning_from_scratch.ch02_ex import generate_text_basic_stream_cache\n",
    "\n",
    "\n",
    "def generate_text_stream_concat_flex(\n",
    "    model, tokenizer, prompt, device, max_new_tokens,\n",
    "    verbose=False,\n",
    "    generate_func=None,\n",
    "    **generate_kwargs\n",
    "):\n",
    "\n",
    "    if generate_func is None:\n",
    "        generate_func = generate_text_basic_stream_cache\n",
    "\n",
    "    input_ids = torch.tensor(\n",
    "        tokenizer.encode(prompt), device=device\n",
    "    ).unsqueeze(0)\n",
    "\n",
    "    generated_ids = []\n",
    "    for token in generate_func(\n",
    "        model=model,\n",
    "        token_ids=input_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        **generate_kwargs,\n",
    "    ):\n",
    "        next_token_id = token.squeeze(0)\n",
    "        generated_ids.append(next_token_id.item())\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                tokenizer.decode(next_token_id.tolist()),\n",
    "                end=\"\",\n",
    "                flush=True\n",
    "            )\n",
    "    return tokenizer.decode(generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5359f47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \\boxed{20}"
     ]
    }
   ],
   "source": [
    "response = generate_text_stream_concat_flex(\n",
    "    model, tokenizer, prompt, device,\n",
    "    max_new_tokens=2048, verbose=True,\n",
    "    generate_func=generate_text_basic_stream_cache\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d70d731f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To solve the problem, we need to find the value of \\( x \\) such that half the value of \\( 3x - 9 \\) is equal to \\( x + 37 \\).\n",
      "\n",
      "### Step 1: Set up the equation\n",
      "We are given that half the value of \\( 3x - 9 \\) is equal to \\( x + 37 \\). This can be written as:\n",
      "\\[\n",
      "\\frac{1}{2}(3x - 9) = x + 37\n",
      "\\]\n",
      "\n",
      "### Step 2: Eliminate the fraction\n",
      "To eliminate the fraction, multiply both sides of the equation by 2:\n",
      "\\[\n",
      "2 \\cdot \\frac{1}{2}(3x - 9) = 2(x + 37)\n",
      "\\]\n",
      "Simplifying both sides:\n",
      "\\[\n",
      "3x - 9 = 2x + 74\n",
      "\\]\n",
      "\n",
      "### Step 3: Solve for \\( x \\)\n",
      "Subtract \\( 2x \\) from both sides to isolate \\( x \\):\n",
      "\\[\n",
      "3x - 2x - 9 = 74\n",
      "\\]\n",
      "Simplify:\n",
      "\\[\n",
      "x - 9 = 74\n",
      "\\]\n",
      "Add 9 to both sides to solve for \\( x \\):\n",
      "\\[\n",
      "x = 74 + 9\n",
      "\\]\n",
      "\\[\n",
      "x = 83\n",
      "\\]\n",
      "\n",
      "### Final Answer:\n",
      "\\[\n",
      "\\boxed{83}\n",
      "\\]"
     ]
    }
   ],
   "source": [
    "prompt_cot = prompt + \" \\n\\nExplain step by step.\"\n",
    "\n",
    "response_cot = generate_text_stream_concat_flex(\n",
    "    model, tokenizer, prompt_cot, device,\n",
    "    max_new_tokens=2048, verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7b11f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "681f7c48",
   "metadata": {},
   "source": [
    "# Chapter 3: Evaluating Reasoning Models\n",
    "\n",
    "  ## Learning Objectives\n",
    "  - Extract and parse final answers from LLM text responses reliably\n",
    "  - Verify answer correctness using symbolic math solvers (calculator-like verification)\n",
    "  - Build an evaluation pipeline: load model → generate outputs → grade against dataset\n",
    "  - Implement verifiable rewards system (foundation for Chapter 6 reinforcement learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0750dd",
   "metadata": {},
   "source": [
    " <img src=\"figure1.png\" alt=\"Figure 1\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bec3b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "\n",
    "from reasoning_from_scratch.qwen3 import (\n",
    "    download_qwen3_small,\n",
    "    Qwen3Tokenizer,\n",
    "    Qwen3Model,\n",
    "    QWEN_CONFIG_06_B\n",
    ")\n",
    "\n",
    "\n",
    "def load_model_and_tokenizer(\n",
    "    which_model, device, use_compile, local_dir=\"qwen3\"\n",
    "):\n",
    "    if which_model == \"base\":\n",
    "\n",
    "        download_qwen3_small(\n",
    "            kind=\"base\", tokenizer_only=False, out_dir=local_dir\n",
    "        )\n",
    "\n",
    "        tokenizer_path = Path(local_dir) / \"tokenizer-base.json\"\n",
    "        model_path = Path(local_dir) / \"qwen3-0.6B-base.pth\"\n",
    "        tokenizer = Qwen3Tokenizer(tokenizer_file_path=tokenizer_path)\n",
    "\n",
    "    elif which_model == \"reasoning\":\n",
    "\n",
    "        download_qwen3_small(\n",
    "            kind=\"reasoning\", tokenizer_only=False, out_dir=local_dir\n",
    "        )\n",
    "\n",
    "        tokenizer_path = Path(local_dir) / \"tokenizer-reasoning.json\"\n",
    "        model_path = Path(local_dir) / \"qwen3-0.6B-reasoning.pth\"\n",
    "        tokenizer = Qwen3Tokenizer(\n",
    "            tokenizer_file_path=tokenizer_path,\n",
    "            apply_chat_template=True,\n",
    "            add_generation_prompt=True,\n",
    "            add_thinking=True,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid choice: which_model={which_model}\")\n",
    "\n",
    "    model = Qwen3Model(QWEN_CONFIG_06_B)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    if use_compile:\n",
    "        torch._dynamo.config.allow_unspec_int_on_nn_module = True\n",
    "        model = torch.compile(model)\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3a3f294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Silicon GPU (MPS)\n",
      "qwen3-0.6B-base.pth: 100% (1433 MiB / 1433 MiB)\n"
     ]
    }
   ],
   "source": [
    "from reasoning_from_scratch.ch02 import (\n",
    "    get_device\n",
    ")\n",
    "\n",
    "WHICH_MODEL = \"base\"\n",
    "device = get_device()\n",
    "\n",
    "# If you have compatibility issues, try to\n",
    "# uncomment the line below and rerun the notebook\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "model, tokenizer = load_model_and_tokenizer(\n",
    "    which_model=WHICH_MODEL,\n",
    "    device=device,\n",
    "    use_compile=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f53b8281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To find the value of \\( a^2 + b^2 \\) given that \\( a + b = 3 \\) and \\( ab = \\frac{13}{6} \\), we can use the following algebraic identity:\n",
      "\n",
      "\\[\n",
      "a^2 + b^2 = (a + b)^2 - 2ab\n",
      "\\]\n",
      "\n",
      "**Step 1:** Substitute the given values into the equation.\n",
      "\n",
      "\\[\n",
      "a^2 + b^2 = (3)^2 - 2 \\left( \\frac{13}{6} \\right)\n",
      "\\]\n",
      "\n",
      "**Step 2:** Calculate \\( (3)^2 \\).\n",
      "\n",
      "\\[\n",
      "(3)^2 = 9\n",
      "\\]\n",
      "\n",
      "**Step 3:** Calculate \\( 2 \\times \\frac{13}{6} \\).\n",
      "\n",
      "\\[\n",
      "2 \\times \\frac{13}{6} = \\frac{26}{6} = \\frac{13}{3}\n",
      "\\]\n",
      "\n",
      "**Step 4:** Subtract the second result from the first.\n",
      "\n",
      "\\[\n",
      "a^2 + b^2 = 9 - \\frac{13}{3}\n",
      "\\]\n",
      "\n",
      "**Step 5:** Convert 9 to a fraction with a denominator of 3 to perform the subtraction.\n",
      "\n",
      "\\[\n",
      "9 = \\frac{27}{3}\n",
      "\\]\n",
      "\n",
      "\\[\n",
      "a^2 + b^2 = \\frac{27}{3} - \\frac{13}{3} = \\frac{14}{3}\n",
      "\\]\n",
      "\n",
      "**Final Answer:**\n",
      "\n",
      "\\[\n",
      "\\boxed{\\dfrac{14}{3}}\n",
      "\\]"
     ]
    }
   ],
   "source": [
    "from reasoning_from_scratch.ch02_ex import (\n",
    "    generate_text_basic_stream_cache\n",
    ")\n",
    "\n",
    "prompt = (\n",
    "    r\"If $a+b=3$ and $ab=\\tfrac{13}{6}$, \"\n",
    "    r\"what is the value of $a^2+b^2$?\"\n",
    ")\n",
    "\n",
    "# Similar to chapter 2 exercise solution:\n",
    "input_token_ids_tensor = torch.tensor(\n",
    "    tokenizer.encode(prompt),\n",
    "    device=device\n",
    "    ).unsqueeze(0)\n",
    "\n",
    "all_token_ids = []\n",
    "for token in generate_text_basic_stream_cache(\n",
    "    model=model,\n",
    "    token_ids=input_token_ids_tensor,\n",
    "    max_new_tokens=2048,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    "):\n",
    "    token_id = token.squeeze(0)\n",
    "    decoded_id = tokenizer.decode(token_id.tolist())\n",
    "    print(\n",
    "        decoded_id,\n",
    "        end=\"\",\n",
    "        flush=True\n",
    "    )\n",
    "    all_token_ids.append(token_id)\n",
    "\n",
    "all_tokens = tokenizer.decode(all_token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e7efb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (reasoning-from-scratch)",
   "language": "python",
   "name": "reasoning-from-scratch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
